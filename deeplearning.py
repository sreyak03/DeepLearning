# -*- coding: utf-8 -*-
"""DEEPLEARNING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JeJD6yj-t6Q7jxL5nFY1iCgwDXKgzGkr
"""

import numpy as np
class Perceptron:
  def __init__(self,input_size,learning_rate=0.1,epoch=100):
    self.weights=np.zeros(input_size)
    self.bias=0
    self.learning_rate=learning_rate
    self.epoch=epoch

  def activation(self,x):
    return 1 if x>=0 else 0 #step function


    # the train method is responsible for training the perceptron model using
  # labeled input data it follows the perceptron learning algorithm,adjusting
  # weights iteratively based on classification errors

  def predict(self,x):
    z=np.dot(self.weights,x)+self.bias
    return self.activation(z)


  def train(self,X,y):
    for epoch in range(self.epoch):
      updates=0
      for i in range(len(X)):
        prediction=self.predict(X[i])
        error=y[i]-prediction
        if error !=0:
          self.weights+=self.learning_rate*error*X[i]
          self.bias+=self.learning_rate*error
          updates+=1
      if updates==0:
        print("converged at epoch",epoch+1)
        break
X=np.array([[0,0],[0,1],[1,0],[1,1]])
y=np.array([0,0,0,1])

perceptron=Perceptron(input_size=2)
perceptron.train(X,y)

for x in X:
  print("input",x,'predicted output',perceptron.predict(x))

import pandas as pd
import numpy as np
url="https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv"
df=pd.read_csv(url)
df.head()

import pandas as pd

# Step 1: Load the dataset
file_path = "https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv"  # Update with your actual file path
df = pd.read_csv(file_path)

# Step 2: Display unique species in the dataset
print("Unique species in dataset:", df['species'].unique())

# Step 3: Filter the dataset for only two species: 'setosa' and 'versicolor'
binary_df = df[df['species'].isin(['setosa', 'versicolor'])].copy()

# Step 4: Convert species column to binary values (setosa = 0, versicolor = 1)
binary_df['species'] = binary_df['species'].map({'setosa': 0, 'versicolor': 1})

# Step 5: Save the new dataset
binary_file_path = "iris_binary.csv"
binary_df.to_csv(binary_file_path, index=False)

print(f"Binary dataset saved to {binary_file_path}")

import numpy as np
import pandas as pd

class Perceptron:
    def __init__(self, input_size, learning_rate=0.1, epoch=100):
        self.weights = np.zeros(input_size)
        self.bias = 0
        self.learning_rate = learning_rate
        self.epoch = epoch

    def activation(self, x):
        return 1 if x >= 0 else 0  # Step function

    def predict(self, x):
        z = np.dot(self.weights, x) + self.bias
        return self.activation(z)

    def train(self, X, y):
        for epoch in range(self.epoch):
            updates = 0
            for i in range(len(X)):
                prediction = self.predict(X[i])
                error = y[i] - prediction
                if error != 0:
                    self.weights += self.learning_rate * error * X[i]
                    self.bias += self.learning_rate * error
                    updates += 1
            if updates == 0:
                print("Converged at epoch", epoch + 1)
                break

# Load dataset
file_path = "https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv"
df = pd.read_csv(file_path)

# Convert categorical target variable to binary (Setosa = 1, Others = 0)
df['species'] = df['species'].apply(lambda x: 1 if x == 'setosa' else 0)

# Extract features and labels
X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values
y = df['species'].values

# Train perceptron
perceptron = Perceptron(input_size=4)
perceptron.train(X, y)

# Testing
for x in X[:5]:  # Display predictions for first 5 samples
    print("Input:", x, 'Predicted Output:', perceptron.predict(x))

"""# MLP
20-2-2025
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np

class DigitRecognizer:
  def __init__(self,input_shape=(28,28),num_classes=10):
    self.input_shape=input_shape
    self.num_classes=num_classes
    self.model=self._build_model()

  def _build_model(self):
    model=Sequential([Flatten(input_shape=self.input_shape),Dense(128,activation='relu'),Dense(self.num_classes,activation='softmax')])
    model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])
    return model
  def train(self,x_train,y_train,x_val,y_val,batch_size=32,epochs=10):
    history =self.model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=epochs,batch_size=batch_size)
    return history
  def evaluate(self,x_test,y_test):
    loss,accuracy=self.model.evaluate(x_test,y_test)
    print(f"test accuracy:{accuracy*100:.2f}%")
    return loss,accuracy

  def predict(self,image):
    image=image.reshape(1,28,28)
    prediction=self.model.predict(image)
    return np.argmax(prediction)

  def plot_training_history(self,history):
    plt.plot(history.history['accuracy'],label='training accuracy')
    plt.plot(history.history['val_accuracy'],label='validation accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Training Progress')
    plt.show()

#load dataset

(x_train,y_train),(x_test,y_test)=mnist.load_data()
x_train,x_test=x_train/255.0,x_test/255.0 #Normalize images
y_train,y_test=to_categorical(y_train,10),to_categorical(y_test,10)

#split validation set
x_val,y_val=x_train[-10000:],y_train[-10000:]
x_train,y_train=x_train[:-10000:],y_train[:-10000]

#Intialize and train model

digit_recongnizer=DigitRecognizer()
history=digit_recongnizer.train(x_train,y_train,x_val,y_val,epochs=10,batch_size=32)
digit_recongnizer.plot_training_history(history)

#evaluate model
digit_recongnizer.evaluate(x_test,y_test)

#test on a single image
sample_image=x_test[0]
predicted_digit=digit_recongnizer.predict(sample_image)
print(f"predicted digit:{predicted_digit}")

#Display the image
plt.imshow(sample_image,cmap='gray')
plt.axis('off')
plt.show()

"""Back propogation

"""



